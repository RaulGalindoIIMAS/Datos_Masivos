{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dcb07045-5e14-42f1-8971-c7d242065ae0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Carga de bibliotecas\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('operaciones_basicas').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c514ec28-1291-4d9e-bebb-dfe4bb249740",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ejemplo básico con foreach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f32b352e-b3ff-4eef-b3fe-3d09b4b37827",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Total del acumulador: 50\n",
       "rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[48] at parallelize at command-995966193448851:3\n",
       "ACC: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 996, name: Some(Acumulador), value: 50)\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Total del acumulador: 50\nrdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[48] at parallelize at command-995966193448851:3\nACC: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 996, name: Some(Acumulador), value: 50)\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "\n",
    "/*Definiendo un RDD usando scala*/\n",
    "val rdd = spark.sparkContext.parallelize(Seq(5,10,15,20)) \n",
    "\n",
    "/* Creando una nueva variable */\n",
    "val ACC = spark.sparkContext.longAccumulator(\"Acumulador\")\n",
    "\n",
    "/* Foreach, su única función es sumar cada uno de los elementos del RDD y almacenar el resultado en la variable ACC*/\n",
    "rdd.foreach(f => {ACC.add(f)})\n",
    "\n",
    "/* Se imprime el resultado */\n",
    "println(\"Total del acumulador: \" + ACC.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "387dcd71-68ef-4d3a-8ac9-94fcb9fcf309",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ejemplo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "814ab833-62d5-40a8-bab5-698f34af60cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">data: Seq[(String, Int)] = List((Dogs,100), (Cats,50), (Lions,10), (Monkeys,30))\n",
       "df: org.apache.spark.sql.DataFrame = [Animal: string, Population: int]\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">data: Seq[(String, Int)] = List((Dogs,100), (Cats,50), (Lions,10), (Monkeys,30))\ndf: org.apache.spark.sql.DataFrame = [Animal: string, Population: int]\n</div>",
       "datasetInfos": [
        {
         "name": "df",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "Animal",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Population",
            "nullable": false,
            "type": "integer"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "org.apache.spark.sql.DataFrame"
        }
       ],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "/*Definiendo un diccionario en scala*/\n",
    "val data = Seq((\"Dogs\",100), (\"Cats\",50),(\"Lions\",10),(\"Monkeys\",30))\n",
    "\n",
    "/* Convirtiendo la lista a DataFrame */\n",
    "val df = spark.createDataFrame(data).toDF(\"Animal\",\"Population\")\n",
    "\n",
    "/* Pasando un foreach */\n",
    "df.foreach(f=> println(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f2a681fd-3bfe-491a-a379-261ef6a3dea3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Accumulator value:190\n",
       "longAcc: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 1058, name: Some(Acumulador), value: 190)\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Accumulator value:190\nlongAcc: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 1058, name: Some(Acumulador), value: 190)\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "/* Creando una nueva variable */\n",
    "val longAcc = spark.sparkContext.longAccumulator(\"Acumulador\")\n",
    "\n",
    "/* For each, va a recorrer internamente cada elemento, y sumará lo que contiene la columna \"Population\" */\n",
    "df.foreach(f=> {longAcc.add(f.getInt(1))})\n",
    "\n",
    "/* Se imprime el resultado */\n",
    "println(\"Accumulator value:\"+longAcc.value)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "operaciones_basicas",
   "notebookOrigID": 2078546801909618,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
